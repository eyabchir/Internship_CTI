{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359d3a75-2dab-4d14-9c17-51f96492f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        line = file.readline().strip()\n",
    "        # Assuming the file contains only one line with the format KEY=value\n",
    "        key, value = line.split('=', 1)\n",
    "        return value\n",
    "\n",
    "# Use the API key\n",
    "GROQ_API_KEY = get_api_key('api_key_llama2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c20c23-cacf-4fdd-a155-872f0769fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\aya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e8183-7f82-4636-bcc8-b694ab357029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Prompts:  94%|█████████████████████████████████████████████████████████▎   | 94/100 [03:50<00:16,  2.74s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to read the API key\n",
    "def get_api_key(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        line = file.readline().strip()\n",
    "        key, value = line.split('=', 1)\n",
    "        return value\n",
    "\n",
    "# Use the API key\n",
    "GROQ_API_KEY = get_api_key('api_key_llama2.txt')\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cti-mcq.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "# Define the start and end lines for processing\n",
    "start_line = 950\n",
    "end_line = 1000\n",
    "df_limited = df.iloc[start_line:end_line]\n",
    "\n",
    "# Define the new prompt format\n",
    "My_prompt = \"\"\"You are given a multiple-choice question (MCQ) from a Cyber Threat Intelligence (CTI) knowledge benchmark dataset. Your task is to choose the best option among the four provided. Return your answer as a single uppercase letter: A, B, C, or D. :\n",
    "\n",
    "### Question: \n",
    "{Question}\n",
    "\n",
    "### Input:\n",
    "A) {Option_A}\n",
    "B) {Option_B}\n",
    "C) {Option_C}\n",
    "D) {Option_D}\n",
    "\n",
    "### Response: \"\"\"\n",
    "\n",
    "# Path to the output TSV file\n",
    "output_file = 'responses_llama3-8B.tsv'\n",
    "\n",
    "# Write the responses to the TSV file\n",
    "with open(output_file, 'a') as file:\n",
    "   \n",
    "    for index, row in tqdm(df_limited.iterrows(), total=df_limited.shape[0], desc=\"Processing Prompts\"):\n",
    "        # Prepare the prompt using the new format\n",
    "        prompt = My_prompt.format(\n",
    "            Question=row['Question'],\n",
    "            Option_A=row['Option A'],\n",
    "            Option_B=row['Option B'],\n",
    "            Option_C=row['Option C'],\n",
    "            Option_D=row['Option D']\n",
    "        )\n",
    "\n",
    "        # Get the response from the llama3 model using Groq\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-8b-8192\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=1,\n",
    "            max_tokens=50,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # Extract and clean the response\n",
    "        response_text = completion.choices[0].message.content.strip()\n",
    "        cleaned_response = response_text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "        # Write the response to the TSV file\n",
    "        file.write(f'{cleaned_response}\\n')\n",
    "\n",
    "        # Sleep for 3 seconds between requests to avoid rate-limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"TSV file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c62a48-2b7c-4a9e-8127-effee88505fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded with encoding: utf-8\n",
      "First letters extracted and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract the first standalone uppercase letter A, B, C, or D\n",
    "def extract_first_letter(content):\n",
    "    if isinstance(content, str):\n",
    "        # Use regex to match variations like \"A)\", \" A \", \"**A**\"\n",
    "        match = re.search(r'\\b[A-D]\\b|\\b[A-D]\\)|\\*\\*[A-D]\\*\\*', content)\n",
    "        if match:\n",
    "            # Clean the match to return just the letter\n",
    "            letter = match.group(0)\n",
    "            return re.sub(r'[^A-D]', '', letter)  # Remove any extra characters like **, )\n",
    "        return ''\n",
    "    return ''\n",
    "\n",
    "# Path to the existing TSV file with responses\n",
    "input_file = 'responses_llama3-8B.tsv'\n",
    "\n",
    "# Attempt to load the responses from the TSV file with different encodings\n",
    "encodings = ['utf-8', 'latin1', 'utf-16', 'ISO-8859-1']  # List of encodings to try\n",
    "df = None\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, sep='\\t', header=None, names=['Response'], encoding=encoding, engine='python')\n",
    "        print(f\"Successfully loaded with encoding: {encoding}\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Failed to load with encoding {encoding}: {e}\")\n",
    "\n",
    "if df is None:\n",
    "    raise ValueError(\"Failed to load the file with all attempted encodings.\")\n",
    "\n",
    "# Prepare a list to hold the results\n",
    "letters = []\n",
    "\n",
    "# Extract the first standalone letter from each response\n",
    "for content in df['Response']:\n",
    "    letter = extract_first_letter(content)\n",
    "    letters.append(letter)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "letters_df = pd.DataFrame({'first_letter': letters})\n",
    "\n",
    "# Save to a new TSV file\n",
    "output_file = 'LLAMMA3_RESPONSES.tsv'\n",
    "letters_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(\"First letters extracted and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d91a6e9-84b7-4836-97f0-0dcfd0c93228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bonnes réponses du modèle (Llama3) est : 37.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "encodings = ['utf-8', 'latin1', 'utf-16', 'ISO-8859-1']  # List of encodings to try\n",
    "\n",
    "df = pd.read_csv('cti-mcq.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "llama_responses = pd.read_csv('LLAMMA3_RESPONSES.tsv', sep='\\t',encoding='utf-8')\n",
    "\n",
    "# Extraire les 900 premières lignes pour les réponses correctes (GT) et les réponses générées\n",
    "gt_answers = df['GT'].head(900).tolist()  # Liste des réponses correctes\n",
    "generated_answers = llama_responses['first_letter'].head(900).tolist()  # Liste des réponses générées\n",
    "\n",
    "# Comparer les réponses et calculer le pourcentage de bonnes réponses\n",
    "correct_answers = 0\n",
    "total_questions = len(gt_answers)  # Devrait être 900\n",
    "\n",
    "# Comparaison des deux colonnes\n",
    "for gt, generated in zip(gt_answers, generated_answers):\n",
    "    if gt == generated:\n",
    "        correct_answers += 1\n",
    "\n",
    "# Calcul du pourcentage de bonnes réponses\n",
    "accuracy_percentage = (correct_answers / total_questions) * 100\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Le pourcentage de bonnes réponses du modèle (Llama3) est : {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fca6c-e384-4a3c-90ef-4ddcbefb293e",
   "metadata": {},
   "source": [
    "#### Comparer les réponses de LLAMA3 sur cti_mcq avec les réponses du dataset du benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae8f280-650d-41b9-9f31-e8afb827964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bonnes réponses du modèle (Llama3) est : 44.33%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "encodings = ['utf-8', 'latin1', 'utf-16', 'ISO-8859-1']  # List of encodings to try\n",
    "\n",
    "df = pd.read_csv('cti-mcq-responses.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "llama_responses = pd.read_csv('LLAMMA3_RESPONSES.tsv', sep='\\t',encoding='utf-8')\n",
    "\n",
    "# Extraire les 900 premières lignes pour les réponses correctes (GT) et les réponses générées\n",
    "gt_answers = df['LLAMA3-8B'].head(900).tolist()  # Liste des réponses correctes\n",
    "generated_answers = llama_responses['first_letter'].head(900).tolist()  # Liste des réponses générées\n",
    "\n",
    "# Comparer les réponses et calculer le pourcentage de bonnes réponses\n",
    "correct_answers = 0\n",
    "total_questions = len(gt_answers)  # Devrait être 900\n",
    "\n",
    "# Comparaison des deux colonnes\n",
    "for gt, generated in zip(gt_answers, generated_answers):\n",
    "    if gt == generated:\n",
    "        correct_answers += 1\n",
    "\n",
    "# Calcul du pourcentage de bonnes réponses\n",
    "accuracy_percentage = (correct_answers / total_questions) * 100\n",
    "\n",
    "# Afficher le résultat\n",
    "print(f\"Le pourcentage de bonnes réponses du modèle (Llama3) est : {accuracy_percentage:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
